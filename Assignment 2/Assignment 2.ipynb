{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json, sys, socket, mimetypes\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################# Helper Methods ################\n",
    "def get_domain(request):\n",
    "    domain = [x['value'] for x in request['headers'] if x['name'] == 'Host']\n",
    "    if len(domain) == 1:\n",
    "        return domain[0]\n",
    "    url = request['url']\n",
    "    if '/' in url:\n",
    "        url_split = url.split('/')\n",
    "        if 'http' in url_split[0]:\n",
    "            return url_split[2]\n",
    "        else:\n",
    "            return url_split[0]\n",
    "    else:\n",
    "        return url\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################# Helper Methods ################\n",
    "def make_request_str(request_dict):\n",
    "    method = request_dict['method']\n",
    "    if method != \"GET\":\n",
    "        print(\"Non-GET method - \",method)\n",
    "        return 'Invalid'\n",
    "    url = request_dict['url']\n",
    "    http_ver = request_dict['httpVersion']\n",
    "    header_str = ''.join([x['name'] + \": \" + x['value'] + \"\\r\\n\" for x in request_dict['headers'] if x['name'] != 'Accept-Encoding'])\n",
    "    request_str = method + \" \" + url + \" \" + http_ver + \"\\r\\n\" + header_str + \"\\r\\n\"\n",
    "    return bytes(request_str,'utf-8')\n",
    "\n",
    "def parse_response_header(response_header):\n",
    "    response_split = response_header.split('\\r\\n')\n",
    "    response_dict = {}\n",
    "    for x in response_split:\n",
    "        y = x.split(': ')\n",
    "        if len(y) > 1:\n",
    "            response_dict.update({y[0]:y[1]})\n",
    "    return response_dict\n",
    "\n",
    "def get_file_extension(mime_type):\n",
    "    ext = mimetypes.guess_extension(mime_type)\n",
    "    if ext == None:\n",
    "        mime_split = mime_type.split('/')\n",
    "        ext = '.' + (mime_split[-1] if mime_split[0] == 'image' or mime_split[0] == 'audio' or mime_split[0] == 'video' else 'txt')\n",
    "    return ext\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################ HAR Data Parsing ###############\n",
    "def har_parser(json_filepath):\n",
    "    with open(json_filepath) as json_data:\n",
    "        data = json.load(json_data)\n",
    "\n",
    "    essential_df_col = ['connection_id','domain','total_time','requestSize','responseStatus','contentSize','request_dict']\n",
    "    essential_df = pd.DataFrame(columns=essential_df_col)\n",
    "    timing_df = pd.DataFrame()\n",
    "\n",
    "    for idx, entry in enumerate(data['log']['entries']):\n",
    "        t_df = pd.DataFrame(entry['timings'],index=[0])\n",
    "        connection_id = entry.get('connection',np.nan)\n",
    "        total_time = sum(t_df[t_df >= 0].iloc[0].fillna(0))\n",
    "        domain = get_domain(entry['request'])\n",
    "        requestSize = entry['request']['headersSize'] + entry['request']['bodySize']\n",
    "        responseStatus = entry['response']['status']\n",
    "        contentSize = entry['response']['content']['size']\n",
    "        request_dict = entry['request']\n",
    "        essential_df.loc[idx] = [connection_id,domain,total_time,requestSize,responseStatus,contentSize,request_dict]\n",
    "        timing_df = timing_df.append(t_df, ignore_index=True)\n",
    "\n",
    "    essential_df = essential_df.reindex_axis(essential_df_col + list(essential_df.columns.drop(essential_df_col)), axis=1)\n",
    "    complete_df = pd.concat([essential_df,timing_df], axis=1)\n",
    "    return data, essential_df, complete_df\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################ Domain Analysis ################\n",
    "def domain_wise_analyser(data,complete_df):\n",
    "    domain_grouping = complete_df.groupby('domain')\n",
    "    analysis_df_col =['Domain','# Objects','# Non-Zero Objects','Content Size','# Connections',\"Connection Analysis\"]\n",
    "    analysis_df = pd.DataFrame(columns=analysis_df_col)\n",
    "    for idx, x in enumerate(domain_grouping):\n",
    "        domain_name = x[0]\n",
    "        content_size = x[1]['contentSize'].sum()\n",
    "        object_count = len(x[1])\n",
    "        non_zero_object_count = (x[1]['contentSize'] > 0).sum()\n",
    "        connection_count = len(x[1])\n",
    "        connection_grouping = x[1].groupby('connection_id')\n",
    "        connection_analysis_df = pd.DataFrame(columns=['Connection ID','# Objects','# Non-Zero Objects','Content Size','DNS'])\n",
    "        for idy, y in enumerate(connection_grouping):\n",
    "            connection_analysis_df.loc[idy] = [y[0],len(y[1]),(y[1]['contentSize'] > 0).sum(),y[1]['contentSize'].sum(),list(y[1]['dns'])]\n",
    "        analysis_df.loc[idx] = [domain_name,object_count,non_zero_object_count,content_size,connection_count,connection_analysis_df]\n",
    "    return analysis_df\n",
    "\n",
    "def print_domain_wise_analysis(analysis_df):\n",
    "    analysis_df_col = analysis_df.columns\n",
    "    print_domain_analysis = input(\"\\33[93mEnter 'y' to see Domain-wise analysis: \\33[0m\")\n",
    "    if print_domain_analysis == 'y':\n",
    "        print('-------------------------------------------------------')\n",
    "        for x in range(analysis_df.shape[0]):\n",
    "            print('\\33[91m',analysis_df_col[0],'\\33[0m',\"\\t-\\t\",'\\33[95m',analysis_df.iloc[x][0],'\\33[0m')\n",
    "            print('\\33[92m',analysis_df_col[1],'\\33[0m',\"\\t-\\t\",'\\33[94m',analysis_df.iloc[x][1],'\\33[0m')\n",
    "            print('\\33[92m',analysis_df_col[2],'\\33[0m',\"\\t-\\t\",'\\33[94m',analysis_df.iloc[x][2],'\\33[0m')\n",
    "            print('\\33[92m',analysis_df_col[3],'\\33[0m',\"-\\t\",'\\33[94m',analysis_df.iloc[x][3],'\\33[0m')\n",
    "            print('\\33[92m',analysis_df_col[4],'\\33[0m',\"-\\t\",'\\33[94m',analysis_df.iloc[x][4],'\\33[0m')\n",
    "            print('\\33[93m',analysis_df_col[5],'\\33[0m')\n",
    "            print(analysis_df.iloc[x][5].to_string(index=False))\n",
    "            print('-------------------------------------------------------')\n",
    "\n",
    "    print('\\33[92mTotal Number of Domains\\33[0m - \\33[95m',analysis_df.shape[0],'\\33[0m')\n",
    "    print('\\33[92mTotal Number of Objects Downloaded\\33[0m - \\33[95m',analysis_df['# Objects'].sum(),'\\33[0m')\n",
    "    print('\\33[92mTotal Number of Non-Zero Objects Downloaded\\33[0m - \\33[95m',analysis_df['# Non-Zero Objects'].sum(),'\\33[0m')\n",
    "    print('\\33[92mTotal Content Downloaded\\33[0m - \\33[95m{0:.2f} MB\\33[0m'.format(analysis_df['Content Size'].sum()/1024**2))\n",
    "    print('\\33[92mPage Load Time\\33[0m - \\33[95m{0:.3f} s\\33[0m'.format(data['log']['pages'][0]['pageTimings']['onLoad']/1000))\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############ TCP Connection Analysis ############\n",
    "def connection_wise_analyser(data,complete_df):\n",
    "    connection_grouping = complete_df.groupby('connection_id')\n",
    "    tcp_analysis_df_col = ['Connection ID','Connect Time','Average Wait Time','Total Receive Time','Total Content Size','Average Goodput','Maximum Goodput']\n",
    "    tcp_analysis_df = pd.DataFrame(columns=tcp_analysis_df_col)\n",
    "    for idx, x in enumerate(connection_grouping):\n",
    "        connect_time = np.max(x[1]['connect'])\n",
    "        avg_wait_time = x[1]['wait'].sum()/len(x[1])\n",
    "        total_receive_time = x[1]['receive'].sum()\n",
    "        total_content_size = x[1]['contentSize'].sum()\n",
    "        avg_goodput = 0 if total_content_size == 0 else float('inf') if total_receive_time == 0 else total_content_size/total_receive_time\n",
    "        max_object_size_idx = np.argmax(x[1]['contentSize'])\n",
    "        max_goodput = 0 if x[1]['contentSize'][max_object_size_idx] == 0 else float('inf') if x[1]['receive'][max_object_size_idx] == 0 else x[1]['contentSize'][max_object_size_idx]/x[1]['receive'][max_object_size_idx]\n",
    "        tcp_analysis_df.loc[idx] = [x[0],connect_time,avg_wait_time,total_receive_time,total_content_size,avg_goodput,max_goodput]\n",
    "    return tcp_analysis_df\n",
    "\n",
    "def print_connection_wise_analysis(tcp_analysis_df):\n",
    "    tcp_analysis_df_col = tcp_analysis_df.columns\n",
    "    print_tcp_analysis = input(\"\\33[93mEnter 'y' to see TCP Connection-wise analysis: \\33[0m\")\n",
    "    if print_tcp_analysis == 'y':\n",
    "        print('-------------------------------------------------------')\n",
    "        for x in range(tcp_analysis_df.shape[0]):\n",
    "            print('\\33[91m',tcp_analysis_df_col[0],'\\33[0m',\"\\t-\\t\",'\\33[95m',tcp_analysis_df.iloc[x][0],'\\33[0m')\n",
    "            print('\\33[92m',tcp_analysis_df_col[1],'\\33[0m',\"\\t\\t-\\t\",'\\33[94m',tcp_analysis_df.iloc[x][1],'\\33[0m')\n",
    "            print('\\33[92m',tcp_analysis_df_col[2],'\\33[0m',\"\\t-\\t\",'\\33[94m',tcp_analysis_df.iloc[x][2],'\\33[0m')\n",
    "            print('\\33[92m',tcp_analysis_df_col[3],'\\33[0m',\"\\t-\\t\",'\\33[94m',tcp_analysis_df.iloc[x][3],'\\33[0m')\n",
    "            print('\\33[92m',tcp_analysis_df_col[4],'\\33[0m',\"\\t-\\t\",'\\33[94m',tcp_analysis_df.iloc[x][4],'\\33[0m')\n",
    "            print('\\33[92m',tcp_analysis_df_col[5],'\\33[0m',\"\\t-\\t\",'\\33[94m',tcp_analysis_df.iloc[x][5],'\\33[0m')\n",
    "            print('\\33[92m',tcp_analysis_df_col[6],'\\33[0m',\"\\t-\\t\",'\\33[94m',tcp_analysis_df.iloc[x][6],'\\33[0m')\n",
    "            print('-------------------------------------------------------')\n",
    "\n",
    "    total_network_receive_time = tcp_analysis_df['Total Receive Time'].sum()/1000\n",
    "    total_network_content_size = tcp_analysis_df['Total Content Size'].sum()/1024**2\n",
    "    print('\\33[92mTotal Number of Connections\\33[0m - \\33[95m',tcp_analysis_df.shape[0],'\\33[0m')\n",
    "    print('\\33[92mTotal Content Downloaded\\33[0m - \\33[95m{0:.2f} MB\\33[0m'.format(total_network_content_size))\n",
    "    print('\\33[92mTotal Receive Time\\33[0m - \\33[95m{0:.2f} s\\33[0m'.format(total_network_receive_time))\n",
    "    # TODO - Check Average Network Goodput Def.\n",
    "    print('\\33[92mAverage Network Goodput\\33[0m - \\33[95m{0:.2f} MB/s\\33[0m'.format(total_network_content_size/total_network_receive_time))\n",
    "    print('\\33[92mMaximum Network Goodput\\33[0m - \\33[95m{0:.2f} MB/s\\33[0m'.format(np.max(tcp_analysis_df['Maximum Goodput'][tcp_analysis_df['Maximum Goodput'] < float('inf')]*(1000/(1024**2)))))\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 'y' to see Domain-wise analysis: \\\n",
      "\u001b[92mTotal Number of Domains\u001b[0m - \u001b[95m 71 \u001b[0m\n",
      "\u001b[92mTotal Number of Objects Downloaded\u001b[0m - \u001b[95m 344 \u001b[0m\n",
      "\u001b[92mTotal Number of Non-Zero Objects Downloaded\u001b[0m - \u001b[95m 299 \u001b[0m\n",
      "\u001b[92mTotal Content Downloaded\u001b[0m - \u001b[95m5.47 MB\u001b[0m\n",
      "\u001b[92mPage Load Time\u001b[0m - \u001b[95m11.203 s\u001b[0m\n",
      "Enter 'y' to see TCP Connection-wise analysis: \n",
      "\u001b[92mTotal Number of Connections\u001b[0m - \u001b[95m 101 \u001b[0m\n",
      "\u001b[92mTotal Content Downloaded\u001b[0m - \u001b[95m5.47 MB\u001b[0m\n",
      "\u001b[92mTotal Receive Time\u001b[0m - \u001b[95m3.53 s\u001b[0m\n",
      "\u001b[92mAverage Network Goodput\u001b[0m - \u001b[95m1.55 MB/s\u001b[0m\n",
      "\u001b[92mMaximum Network Goodput\u001b[0m - \u001b[95m22.98 MB/s\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "###### Testing ######\n",
    "json_filepath = 'data/HAR Dumps/Indian Express/unthrottled_windows.har'\n",
    "data, essential_df, complete_df = har_parser(json_filepath)\n",
    "analysis_df = domain_wise_analyser(data,complete_df)\n",
    "tcp_analysis_df = connection_wise_analyser(data,complete_df)\n",
    "print_domain_wise_analysis(analysis_df)\n",
    "print_connection_wise_analysis(tcp_analysis_df)\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############# Object Download Method ############\n",
    "def get_object(sck,request_dict):\n",
    "    request = make_request_str(request_dict)\n",
    "    domain = [headers['value'] for headers in request_dict['headers'] if headers['name'] == 'Host']\n",
    "    if request != \"Invalid\":\n",
    "        try:\n",
    "            sck.connect((domain[0],80))\n",
    "            sck.send(request)\n",
    "            response = sck.recv(1024)\n",
    "            header_end = response.find(bytes(\"\\r\\n\\r\\n\",'utf-8'))+len(\"\\r\\n\\r\\n\")\n",
    "            response_header = response[:header_end] if header_end > 3 else response\n",
    "            content_start = 1 if header_end > 3 else -1\n",
    "            content = response[header_end:] if content_start == 1 else \"\"\n",
    "            while len(response) > 0:\n",
    "                response = sck.recv(1024)\n",
    "                if content_start == -1:\n",
    "                    add_response = response_header + response\n",
    "                    header_end = add_response.find(bytes(\"\\r\\n\\r\\n\",'utf-8'))+len(\"\\r\\n\\r\\n\")\n",
    "                    response_header = add_response[:header_end] if header_end > 3 else add_response\n",
    "                    content_start = 1 if header_end > 3 else -1\n",
    "                    content = add_response[header_end:] if content_start == 1 else \"\"\n",
    "                else:\n",
    "                    content = content + response\n",
    "            return (str(response_header,'utf-8'),content)\n",
    "        except:\n",
    "            return(\"Error occured\",\"\")\n",
    "    else:\n",
    "        return (\"Invalid request encountered\",\"\")\n",
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exceeded\n",
      "Exceeded\n",
      "Exceeded\n",
      "Exceeded\n"
     ]
    }
   ],
   "source": [
    "max_tcp = 4\n",
    "max_obj = 5\n",
    "json_filepath = 'data/HAR Dumps/Indian Express/unthrottled_windows.har'\n",
    "out_folder = 'out/' + json_filepath.split('/')[2] + ' - ' + json_filepath.split('/')[3].split('.')[0] + '/'\n",
    "domain_grouping = complete_df.groupby('domain')\n",
    "for idx, x in enumerate(domain_grouping):\n",
    "    out_folder_domain = out_folder + x[0]\n",
    "    sorted_data = x[1].sort_values(by='contentSize',axis=0,ascending=True)\n",
    "    obj_count = len(sorted_data)\n",
    "    scks = [socket.socket(socket.AF_INET,socket.SOCK_STREAM) for i in range(min(max_tcp,obj_count))]\n",
    "    if obj_count <= max_tcp * max_obj:\n",
    "        for idk, sck in enumerate(scks):\n",
    "            make_request_str(sorted_data.loc[sorted_data.index[idk]]['request_dict'])\n",
    "    else:\n",
    "        print(\"Exceeded\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = socket.socket(socket.AF_INET,socket.SOCK_STREAM)\n",
    "i = 5\n",
    "req_dict = data['log']['entries'][i]['request']\n",
    "response_header, content = get_object(s,req_dict)\n",
    "s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accept-Ranges :  bytes\n",
      "X-ac :  4.hkg _bur\n",
      "Cache-Control :  max-age=31536000\n",
      "Last-Modified :  Tue, 12 Sep 2017 13:23:50 GMT\n",
      "Connection :  keep-alive\n",
      "Server :  nginx\n",
      "Date :  Sun, 24 Sep 2017 15:23:53 GMT\n",
      "ETag :  \"59b7dfe6-2b6b\"\n",
      "Access-Control-Allow-Methods :  GET, HEAD\n",
      "Vary :  Accept-Encoding\n",
      "Content-Length :  11115\n",
      "Content-Type :  image/svg+xml\n",
      "X-nc :  HIT hkg 32\n",
      "Access-Control-Allow-Origin :  *\n",
      "Expires :  Wed, 12 Sep 2018 13:25:53 GMT\n",
      "Extension:  .svg\n",
      "Content-Length (received):  11115\n"
     ]
    }
   ],
   "source": [
    "response_dict = parse_response_header(response_header)\n",
    "_ = [print(key,\": \",response_dict[key]) for key in response_dict.keys()]\n",
    "ext = get_file_extension(response_dict['Content-Type'])\n",
    "print('Extension: ',ext)\n",
    "print('Content-Length (received): ',len(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
